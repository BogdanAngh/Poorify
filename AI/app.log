[22-May-19 10:41:58 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:41:58 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:41:58 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:41:58 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:42:00 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:42:00 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:42:00 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:42:00 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:42:00 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:42:00 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:42:00 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 10:42:00 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:42:03 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:42:03 | INFO trainer.py:121 -                train() ] Starting the training...
[22-May-19 10:42:27 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:42:27 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:42:27 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:42:27 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:42:28 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:42:28 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:42:28 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:42:28 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:42:28 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:42:28 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:42:28 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 10:42:28 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:42:31 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:42:31 | INFO trainer.py:121 -                train() ] Starting the training...
[22-May-19 10:43:11 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:43:11 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:43:11 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:43:11 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:43:13 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:43:13 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:43:13 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:43:14 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:43:14 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:43:14 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:43:14 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 10:43:14 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:43:16 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:43:16 | INFO trainer.py:121 -                train() ] Starting the training...
[22-May-19 10:44:07 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:44:07 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:44:07 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:44:07 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:44:08 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:44:08 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:44:08 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:44:09 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:44:09 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:44:09 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:44:36 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:44:36 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:44:36 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:44:36 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:44:37 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:44:38 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:44:38 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:44:38 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:44:38 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:44:38 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:44:55 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:44:55 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:44:55 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:44:55 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:44:56 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:44:57 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:44:57 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:44:57 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:44:57 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:44:57 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:45:33 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:45:33 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:45:33 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:45:33 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:45:34 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:45:34 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:45:34 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:45:34 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:45:34 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:45:34 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:45:34 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 10:45:34 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:45:37 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:45:37 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 10:48:38 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 10:48:38 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 10:48:38 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 10:48:38.382201
[22-mai-19 10:48:38 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 10:48:38.382201/my_model.pth
[22-mai-19 10:48:38 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 10:48:38.382201/cm.png
[22-mai-19 10:48:38 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 10:48:38.382201/config.json
[22-mai-19 10:48:38 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 10:49:31 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:49:31 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:49:31 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:49:31 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:49:32 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:49:32 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:49:32 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:49:32 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:49:32 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:49:32 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:49:32 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 10:49:32 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:49:34 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:49:34 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 10:52:23 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 10:52:23 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 10:52:23 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 10:52:23.725064
[22-mai-19 10:52:23 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 10:52:23.725064/my_model.pth
[22-mai-19 10:52:23 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 10:52:23.725064/cm.png
[22-mai-19 10:52:23 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 10:52:23.725064/config.json
[22-mai-19 10:52:23 | INFO train.py:63 -             <module>() ] Training ended!

[22-May-19 10:53:02 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:53:02 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:53:02 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:53:02 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:53:03 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:53:03 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:53:03 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:53:04 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:53:04 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:53:04 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:53:04 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 10:53:04 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:53:06 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:53:06 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 10:53:53 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 10:53:53 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 10:53:53 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 10:53:53.344654
[22-mai-19 10:53:53 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 10:53:53.344654/my_model.pth
[22-mai-19 10:53:53 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 10:53:53.344654/cm.png
[22-mai-19 10:53:53 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 10:53:53.344654/config.json
[22-mai-19 10:53:53 | INFO train.py:63 -             <module>() ] Training ended!

[22-May-19 10:54:03 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 10:54:03 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 10:54:03 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 10:54:03 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 10:54:04 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 10:54:04 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 10:54:04 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 10:54:04 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 10:54:04 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 10:54:04 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 10:54:04 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 10:54:04 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 10:54:07 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 10:54:07 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 10:56:18 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 10:56:18 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 10:56:18 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 10:56:18.470064
[22-mai-19 10:56:18 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 10:56:18.470064/my_model.pth
[22-mai-19 10:56:18 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 10:56:18.470064/cm.png
[22-mai-19 10:56:18 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 10:56:18.470064/config.json
[22-mai-19 10:56:18 | INFO train.py:63 -             <module>() ] Training ended!

[22-May-19 14:58:53 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 14:58:53 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 14:58:53 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 14:58:53 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 14:58:55 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 14:58:55 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 14:58:55 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 14:58:55 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 14:58:55 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 14:58:56 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 14:58:56 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 14:58:56 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 14:59:06 | WARNING train.py:66 -             <module>() ] Keyboard interrupt!

[22-May-19 15:03:21 | INFO utils.py:246 -         load_logging() ] Logger loaded
[22-May-19 15:03:21 | INFO utils.py:232 -          load_config() ] Config loaded!
[22-May-19 15:03:21 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 15:03:21 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 15:03:22 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 15:03:22 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 15:03:22 | INFO utils.py:190 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 15:03:22 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 15:03:22 | INFO utils.py:217 -            load_data() ] Vocab size : 12902
[22-May-19 15:03:22 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 15:03:22 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 15:03:22 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 15:03:26 | WARNING train.py:66 -             <module>() ] Keyboard interrupt!

[22-May-19 15:05:30 | INFO utils.py:246 -         load_logging() ] Logger loaded
[22-May-19 15:05:30 | INFO utils.py:232 -          load_config() ] Config loaded!
[22-May-19 15:05:31 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 15:05:31 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 15:05:32 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 15:05:32 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 15:05:32 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 15:05:32 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 15:05:32 | INFO utils.py:217 -            load_data() ] Vocab size : 12902
[22-May-19 15:05:32 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 15:05:32 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 15:05:32 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 15:05:35 | WARNING train.py:66 -             <module>() ] Keyboard interrupt!

[22-May-19 15:26:58 | INFO utils.py:246 -         load_logging() ] Logger loaded
[22-May-19 15:26:58 | INFO utils.py:232 -          load_config() ] Config loaded!
[22-May-19 15:26:58 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 15:26:58 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 15:26:59 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 15:26:59 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 15:26:59 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 15:26:59 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 15:26:59 | INFO utils.py:217 -            load_data() ] Vocab size : 12902
[22-May-19 15:26:59 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 15:26:59 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 15:26:59 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 15:28:46 | INFO utils.py:246 -         load_logging() ] Logger loaded
[22-May-19 15:28:46 | INFO utils.py:232 -          load_config() ] Config loaded!
[22-May-19 15:28:46 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 15:28:46 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 15:28:47 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 15:28:47 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 15:28:47 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 15:28:47 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 15:28:47 | INFO utils.py:217 -            load_data() ] Vocab size : 12902
[22-May-19 15:28:47 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 15:28:47 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 15:28:47 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 15:29:17 | INFO utils.py:246 -         load_logging() ] Logger loaded
[22-May-19 15:29:17 | INFO utils.py:232 -          load_config() ] Config loaded!
[22-May-19 15:29:17 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 15:29:17 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 15:29:18 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 15:29:18 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 15:29:18 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 15:29:19 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 15:29:19 | INFO utils.py:217 -            load_data() ] Vocab size : 12902
[22-May-19 15:29:19 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 15:29:19 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.5)
  (linear): Linear(in_features=128, out_features=4, bias=True)
)
[22-May-19 15:29:19 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 16:02:22 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:02:22 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:02:22 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:02:22 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:02:23 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:02:23 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:02:23 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:02:23 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:02:23 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:02:23 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:02:24 | INFO model.py:42 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:02:24 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:02:24 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 16:02:42 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:02:42 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:02:42 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:02:42 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:02:43 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:02:43 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:02:43 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:02:43 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:02:43 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:02:43 | INFO model.py:37 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:02:43 | INFO model.py:42 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:02:43 | INFO model.py:51 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:02:43 | INFO model.py:53 -             __init__() ] MyModel created!
[22-May-19 16:02:43 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 16:02:43 | INFO trainer.py:121 -                train() ] Starting the training...
[22-May-19 16:14:34 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:14:34 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:14:34 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:14:34 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:14:35 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:14:35 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:14:35 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:14:35 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:14:35 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:14:35 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:14:35 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:14:35 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:14:35 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 16:14:35 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 16:14:35 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 16:15:51 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 16:15:51 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 16:15:51 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 16:15:51.406205
[22-mai-19 16:15:51 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 16:15:51.406205/my_model.pth
[22-mai-19 16:15:51 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 16:15:51.406205/cm.png
[22-mai-19 16:15:51 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 16:15:51.406205/config.json
[22-mai-19 16:15:51 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 16:16:22 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:16:22 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:16:22 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:16:22 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:16:23 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:16:23 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:16:23 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:16:23 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:16:23 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:16:23 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:16:23 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:16:23 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:16:23 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 16:16:23 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 16:16:23 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 16:22:23 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 16:22:23 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 16:22:23 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 16:22:23.092970
[22-mai-19 16:22:23 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 16:22:23.092970/my_model.pth
[22-mai-19 16:22:23 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 16:22:23.092970/cm.png
[22-mai-19 16:22:23 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 16:22:23.092970/config.json
[22-mai-19 16:22:23 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 16:22:49 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:22:49 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:22:49 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:22:49 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:22:50 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:22:50 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:22:50 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:22:50 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:22:50 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:22:50 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:22:50 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:22:50 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:22:50 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 16:22:50 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 16:22:50 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 16:37:50 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 16:37:50 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 16:37:50.135004
[22-mai-19 16:37:50 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 16:37:50.135004/my_model.pth
[22-mai-19 16:37:50 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 16:37:50.135004/cm.png
[22-mai-19 16:37:50 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 16:37:50.135004/config.json
[22-mai-19 16:37:50 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 16:39:07 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:39:07 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:39:07 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:39:07 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:39:08 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:39:08 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:39:08 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:39:08 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:39:08 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:39:08 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:39:08 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:39:08 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:39:08 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 16:39:08 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 16:39:08 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 16:49:45 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 16:49:45 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 16:49:45 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 16:49:45.462498
[22-mai-19 16:49:45 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 16:49:45.462498/my_model.pth
[22-mai-19 16:49:45 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 16:49:45.462498/cm.png
[22-mai-19 16:49:45 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 16:49:45.462498/config.json
[22-mai-19 16:49:45 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 16:51:38 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 16:51:38 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 16:51:38 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 16:51:38 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 16:51:39 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 16:51:39 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 16:51:39 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 16:51:39 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 16:51:39 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 16:51:39 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 16:51:39 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(128, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(128, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 16:51:39 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 16:51:39 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 16:51:39 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 16:51:39 | INFO trainer.py:121 -                train() ] Starting the training...
[22-mai-19 17:05:49 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 17:05:49 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 17:05:49 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 17:05:49.774638
[22-mai-19 17:05:49 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 17:05:49.774638/my_model.pth
[22-mai-19 17:05:49 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 17:05:49.774638/cm.png
[22-mai-19 17:05:49 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 17:05:49.774638/config.json
[22-mai-19 17:05:49 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 19:53:22 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 19:53:22 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 19:53:22 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 19:53:22 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 19:53:23 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 19:53:23 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 19:53:23 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 19:53:23 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 19:53:23 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 19:53:23 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 19:53:23 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 19:53:23 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 19:53:23 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 19:53:32 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 19:53:32 | INFO trainer.py:117 -                train() ] Starting the training...
[22-mai-19 19:56:03 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 19:56:03 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 19:56:03 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 19:56:03.915283
[22-mai-19 19:56:03 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 19:56:03.915283/my_model.pth
[22-mai-19 19:56:03 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 19:56:03.915283/cm.png
[22-mai-19 19:56:04 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 19:56:03.915283/config.json
[22-mai-19 19:56:04 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 20:09:50 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 20:09:50 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 20:09:51 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 20:09:51 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 20:09:52 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 20:09:52 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 20:09:52 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 20:09:53 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 20:09:53 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 20:09:53 | INFO model.py:38 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 20:09:53 | INFO model.py:43 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 20:09:53 | INFO model.py:52 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 20:09:53 | INFO model.py:54 -             __init__() ] MyModel created!
[22-May-19 21:02:54 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 21:02:54 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 21:02:54 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 21:02:54 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 21:02:55 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 21:02:55 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 21:02:55 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 21:02:55 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 21:02:55 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 21:02:55 | INFO model.py:41 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 21:02:55 | INFO model.py:46 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 21:02:55 | INFO model.py:55 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 21:02:55 | INFO model.py:57 -             __init__() ] MyModel created!
[22-May-19 21:02:57 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 21:02:57 | INFO trainer.py:117 -                train() ] Starting the training...
[22-mai-19 21:05:03 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 21:05:03 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 21:05:03 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 21:05:03.270507
[22-mai-19 21:05:03 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 21:05:03.270507/my_model.pth
[22-mai-19 21:05:03 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 21:05:03.270507/cm.png
[22-mai-19 21:05:03 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 21:05:03.270507/config.json
[22-mai-19 21:05:03 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 21:07:08 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 21:07:08 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 21:07:08 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 21:07:08 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 21:07:09 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 21:07:09 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 21:07:09 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 21:07:09 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 21:07:09 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 21:07:10 | INFO model.py:41 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 21:07:10 | INFO model.py:46 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 21:07:10 | INFO model.py:55 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 21:07:10 | INFO model.py:57 -             __init__() ] MyModel created!
[22-May-19 21:07:12 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 21:07:12 | INFO trainer.py:117 -                train() ] Starting the training...
[22-mai-19 21:09:57 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 21:09:57 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 21:09:57 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 21:09:57.035628
[22-mai-19 21:09:57 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 21:09:57.035628/my_model.pth
[22-mai-19 21:09:57 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 21:09:57.035628/cm.png
[22-mai-19 21:09:57 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 21:09:57.035628/config.json
[22-mai-19 21:09:57 | INFO train.py:62 -             <module>() ] Training ended!

[22-May-19 21:41:46 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 21:41:46 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 21:41:46 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 21:41:46 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 21:41:47 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 21:41:48 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 21:41:48 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 21:41:48 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 21:41:48 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 21:42:21 | INFO model.py:41 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 21:42:21 | INFO model.py:46 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 21:42:21 | INFO model.py:55 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 21:42:21 | INFO model.py:57 -             __init__() ] MyModel created!
[22-May-19 21:42:23 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 21:42:23 | INFO trainer.py:117 -                train() ] Starting the training...
[22-May-19 21:50:05 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 21:50:05 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 21:50:05 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 21:50:05 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 21:50:06 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 21:50:07 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 21:50:07 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 21:50:07 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 21:50:07 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 21:50:07 | INFO model.py:41 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 21:50:07 | INFO model.py:46 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 21:50:07 | INFO model.py:55 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 21:50:07 | INFO model.py:57 -             __init__() ] MyModel created!
[22-May-19 22:02:45 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 22:02:45 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 22:02:45 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 22:02:45 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 22:02:46 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 22:02:46 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 22:02:46 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 22:02:46 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 22:02:46 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 22:02:46 | INFO model.py:41 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 22:02:46 | INFO model.py:46 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 22:02:46 | INFO model.py:55 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 22:02:46 | INFO model.py:57 -             __init__() ] MyModel created!
[22-May-19 22:02:49 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 22:02:49 | INFO trainer.py:117 -                train() ] Starting the training...
[22-mai-19 22:10:47 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 22:10:47 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 22:10:47 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 22:10:47.470881
[22-mai-19 22:10:47 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 22:10:47.470881/my_model.pth
[22-May-19 22:13:00 | INFO utils.py:241 -         load_logging() ] Logger loaded
[22-May-19 22:13:00 | INFO utils.py:227 -          load_config() ] Config loaded!
[22-May-19 22:13:01 | INFO utils.py:125 -       load_train_val() ] Loaded 9966 samples from dataset/train_dataset.csv
[22-May-19 22:13:01 | INFO utils.py:129 -       load_train_val() ] Loaded 3457 samples from dataset/validation_dataset.csv
[22-May-19 22:13:01 | INFO utils.py:108 -         build_loader() ] Created train data loader having 9966 samples and 156 batches of size 64
[22-May-19 22:13:01 | INFO utils.py:108 -         build_loader() ] Created validation data loader having 3457 samples and 55 batches of size 64
[22-May-19 22:13:01 | INFO utils.py:185 -            load_test() ] Loaded 3112 samples from dataset/test_dataset.csv
[22-May-19 22:13:02 | INFO utils.py:108 -         build_loader() ] Created test data loader having 3112 samples and 49 batches of size 64
[22-May-19 22:13:02 | INFO utils.py:212 -            load_data() ] Vocab size : 12902
[22-May-19 22:13:02 | INFO model.py:41 -             __init__() ] Embedding layer created : Embedding(12903, 256)
[22-May-19 22:13:02 | INFO model.py:46 -             __init__() ] Convolutional layer created : Convolution(
  (conv): ModuleList(
    (0): PaddedConvolution(
      (padder): ConstantPad1d(padding=[0, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(2,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (1): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 1], value=0)
      (conv): Conv1d(64, 100, kernel_size=(3,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
    (2): PaddedConvolution(
      (padder): ConstantPad1d(padding=[1, 2], value=0)
      (conv): Conv1d(64, 100, kernel_size=(4,), stride=(1,))
      (bn): BatchNorm1d(100, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (activation): Tanh()
    )
  )
  (pooling): Sequential(
    (0): ConstantPad1d(padding=[0, 1], value=0)
    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
)
[22-May-19 22:13:02 | INFO model.py:55 -             __init__() ] Postnet layer created : Postnet(
  (dropout): Dropout(p=0.2)
  (linear): Linear(in_features=38400, out_features=4, bias=True)
)
[22-May-19 22:13:02 | INFO model.py:57 -             __init__() ] MyModel created!
[22-May-19 22:13:04 | INFO trainer.py:48 -             __init__() ] Trainer created!
[22-May-19 22:13:04 | INFO trainer.py:117 -                train() ] Starting the training...
[22-mai-19 22:15:07 | INFO utils.py:248 -           save_model() ] Creating log directory log/
[22-mai-19 22:15:07 | WARNING utils.py:252 -           save_model() ] Log directory already exists!
[22-mai-19 22:15:07 | INFO utils.py:261 -           save_model() ] Creating model s directory log/2019-05-22 22:15:07.946685
[22-mai-19 22:15:07 | INFO utils.py:268 -           save_model() ] Saving the model at log/2019-05-22 22:15:07.946685/my_model.pth
[22-mai-19 22:15:08 | INFO utils.py:272 -           save_model() ] Saving the confusion matrix at log/2019-05-22 22:15:07.946685/cm.png
[22-mai-19 22:15:08 | INFO utils.py:276 -           save_model() ] Saving the model s config at log/2019-05-22 22:15:07.946685/config.json
[22-mai-19 22:15:08 | INFO train.py:62 -             <module>() ] Training ended!

